{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --upgrade --quiet langchain-openai langchain-community langchainhub langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlglot\n",
      "  Downloading sqlglot-26.2.1-py3-none-any.whl.metadata (19 kB)\n",
      "Downloading sqlglot-26.2.1-py3-none-any.whl (443 kB)\n",
      "Installing collected packages: sqlglot\n",
      "Successfully installed sqlglot-26.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sqlglot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf\n",
      "  Using cached protobuf-5.29.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Using cached protobuf-5.29.3-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Installing collected packages: protobuf\n",
      "Successfully installed protobuf-5.29.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Using cached sentencepiece-0.2.0-cp311-cp311-win_amd64.whl (991 kB)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conexión con base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "usuario = 'postgres'\n",
    "password = 'place_rag_password'\n",
    "host = 'localhost'     # o la IP/URL de tu servidor\n",
    "puerto = '5432'        # puerto por defecto de PostgreSQL\n",
    "base_datos = 'place_rag_db'\n",
    "\n",
    "# Crear la URL de conexión\n",
    "uri = f\"postgresql+psycopg2://{usuario}:{password}@{host}:{puerto}/{base_datos}\"\n",
    "\n",
    "db = SQLDatabase.from_uri(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "api_key= os.environ.get(\"HF_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(db.table_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "Dada una pregunta de entrada, crea una consulta de postgresql sintácticamente correcta.\n",
    "Usa solo los nombres de las columnas que puedes ver en la descripción del esquema.\n",
    "No consultes columnas que no existen.\n",
    "Utiliza únicamente las siguientes tablas: 'entidades', 'expedientes', 'paises', 'regiones'\n",
    "Esquema de la base de datos:\n",
    "{db.table_info}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qwen2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rodrigo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Rodrigo\\.cache\\huggingface\\hub\\models--Qwen--Qwen2-1.5B-Instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"Qwen/Qwen2-0.5B\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ChatMessage\n",
    ")\n",
    "question = \"Muéstrame todas las licitaciones de Navarra que excedan 277000€.\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=system_prompt),\n",
    "    HumanMessage(\n",
    "        content=question\n",
    "    ),\n",
    "    ChatMessage(role=\"assistant\", content=\"SELECT *\"),\n",
    "]\n",
    "ai_msg = chat_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AceInstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"nvidia/AceInstruct-1.5B\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ChatMessage\n",
    ")\n",
    "question = \"Muéstrame todas las licitaciones de Navarra que excedan 277000€.\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=system_prompt),\n",
    "    HumanMessage(\n",
    "        content=question\n",
    "    ),\n",
    "    ChatMessage(role=\"assistant\", content=\"SELECT *\"),\n",
    "]\n",
    "ai_msg = chat_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Openai o1-Mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "os.environ.get(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ChatMessage\n",
    ")\n",
    "question = \"Muéstrame todas las licitaciones de Navarra que excedan 277000€.\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=system_prompt),\n",
    "    HumanMessage(\n",
    "        content=question\n",
    "    ),\n",
    "    ChatMessage(role=\"assistant\", content=\"SELECT *\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft Phi 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionOutputMessage(role='assistant', content=\"\\nFROM expedientes AS e\\nJOIN regiones AS r ON e.party_nif = r.country_subentity_code\\nJOIN paises AS p ON r.country_code = p.country_code\\nJOIN documentos AS d ON e.contract_folder_id = d.contract_id\\nWHERE r.country_subentity_name = 'Navarra' AND e.total_amount > 277000;\", tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(\n",
    "\n",
    "\tapi_key=api_key\n",
    ")\n",
    "question = \"Muéstrame todas las licitaciones de Navarra que excedan 277000€.\"\n",
    "message = f\"{system_prompt} {question}\"\n",
    "messages = [\n",
    "\t{\n",
    "\t\t\"role\": \"user\",\n",
    "\t\t\"content\": message\n",
    "\t},\n",
    "    {\n",
    "\t\t\"role\": \"assistant\",\n",
    "\t\t\"content\": \"SELECT *\"\n",
    "\t}\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"microsoft/Phi-3-mini-4k-instruct\", \n",
    "\tmessages=messages, \n",
    "\tmax_tokens=500\n",
    ")\n",
    "\n",
    "# AÑADIR UN STOP CUNADO SE LLEGUE A ;\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "\n",
    "def query_as_list(db, query):\n",
    "    res = db.run(query)\n",
    "    res = [el for sub in ast.literal_eval(res) for el in sub if el]\n",
    "    res = [re.sub(r\"\\b\\d+\\b\", \"\", string).strip() for string in res]\n",
    "    return list(set(res))\n",
    "\n",
    "entidades = query_as_list(db, \"SELECT name FROM entidades\")\n",
    "tipo_contrato = query_as_list(db, \"SELECT procurement_project_type_code FROM expedientes\")\n",
    "subtipo_contrato = query_as_list(db, \"SELECT procurement_project_subtype_name FROM expedientes\")\n",
    "estado_expediente = query_as_list(db, \"SELECT contract_folder_status_code FROM expedientes\")\n",
    "paises = query_as_list(db, \"SELECT country_name FROM paises\")\n",
    "regiones = query_as_list(db, \"SELECT country_subentity_name FROM regiones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "\n",
    "_ = vector_store.add_texts(entidades + tipo_contrato + subtipo_contrato + estado_expediente + paises + regiones)\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "description = (\n",
    "    \"Use to look up values to filter on. Input is an approximate spelling \"\n",
    "    \"of the proper noun, output is valid proper nouns. Use the noun most \"\n",
    "    \"similar to the search.\"\n",
    ")\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name=\"search_proper_nouns\",\n",
    "    description=description,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medir precisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutar query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDatabaseTool\n",
    "\n",
    "\n",
    "def execute_query(state: State):\n",
    "    \"\"\"Execute SQL query.\"\"\"\n",
    "    execute_query_tool = QuerySQLDatabaseTool(db=db)\n",
    "    return {\"result\": execute_query_tool.invoke(state[\"query\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlglot\n",
    "from sqlglot import parse_one, exp\n",
    "\n",
    "def normalize_sql(query):\n",
    "    \"\"\"\n",
    "    Normaliza una consulta SQL parseándola y generando su representación estándar.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parsed = parse_one(query)\n",
    "        return parsed.to_sql()\n",
    "    except Exception as e:\n",
    "        print(f\"Error al parsear la consulta: {e}\")\n",
    "        return None\n",
    "\n",
    "def son_consultas_equivalentes(sql1, sql2):\n",
    "    \"\"\"\n",
    "    Compara dos consultas SQL para determinar si son estructuralmente equivalentes.\n",
    "    \"\"\"\n",
    "    norm_sql1 = normalize_sql(sql1)\n",
    "    norm_sql2 = normalize_sql(sql2)\n",
    "    \n",
    "    if norm_sql1 is None or norm_sql2 is None:\n",
    "        return False\n",
    "    \n",
    "    return norm_sql1.lower() == norm_sql2.lower()\n",
    "\n",
    "# Ejemplos de consultas\n",
    "consulta1 = \"SELECT a, b FROM tabla WHERE a > 10 ORDER BY b DESC\"\n",
    "consulta2 = \"select b, a from tabla where a > 10 order by b desc\"\n",
    "\n",
    "equivalente = son_consultas_equivalentes(consulta1, consulta2)\n",
    "print(f\"¿Las consultas son equivalentes? {'Sí' if equivalente else 'No'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
