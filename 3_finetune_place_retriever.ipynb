{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning de modelo Deepseek Coder con LoRA y 8-bit\n",
    "\n",
    "Este documento describe un proceso para ajustar finamente (*fine-tune*) un modelo de lenguaje (basado en la arquitectura *deepseek-coder-1.3b-base*) para la generación de consultas SQL, usando:\n",
    "\n",
    "- **LoRA (Low-Rank Adaptation)** para reducir la cantidad de parámetros a entrenar.\n",
    "- **Quantización en 8 bits** a través de *BitsAndBytes* (`bnb_config`), para reducir la huella de memoria y hacer factible el entrenamiento en GPU.\n",
    "\n",
    "A continuación, se describen los pasos para:\n",
    "1. Conectar a la base de datos y obtener su esquema.\n",
    "2. Cargar y preparar un *dataset*.\n",
    "3. Definir un *prompt* con indicaciones claras para la tarea de generación de consultas SQL.\n",
    "4. Entrenar el modelo realizando una búsqueda de hiperparámetros.\n",
    "5. Realizar **dos** *fine-tunings finales* con configuraciones seleccionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conexión con base de datos\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "usuario = 'postgres'\n",
    "password = 'place_rag_password'\n",
    "host = 'localhost'     # o la IP/URL de tu servidor\n",
    "puerto = '5432'        # puerto por defecto de PostgreSQL\n",
    "base_datos = 'place_rag_db'\n",
    "\n",
    "# Crear la URL de conexión\n",
    "uri = f\"postgresql+psycopg2://{usuario}:{password}@{host}:{puerto}/{base_datos}\"\n",
    "\n",
    "# Se instancia la clase SQLDatabase a partir de la URI\n",
    "db = SQLDatabase.from_uri(uri)\n",
    "\n",
    "import os\n",
    "# Cargamos la API key de HF desde las variables de entorno\n",
    "api_key= os.environ.get(\"HF_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y preparación del *dataset*\n",
    "\n",
    "Se carga un archivo CSV de ejemplo (`sampled_place_dataset.csv`) que contiene pares de \"Pregunta\" y \"Consulta\" (SQL) que se usarán en el entrenamiento y la evaluación del modelo. Posteriormente, se renombran columnas según la necesidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregunta</th>\n",
       "      <th>Consulta</th>\n",
       "      <th>Tabla</th>\n",
       "      <th>Valores</th>\n",
       "      <th>Categoría</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quiero ver todas las licitaciones de Principad...</td>\n",
       "      <td>SELECT * FROM expedientes JOIN entidades ON ex...</td>\n",
       "      <td>expedientes</td>\n",
       "      <td>{'region': 'Principado de Asturias'}</td>\n",
       "      <td>region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¿Qué expedientes están registrados en Teruel?</td>\n",
       "      <td>SELECT * FROM expedientes JOIN entidades ON ex...</td>\n",
       "      <td>expedientes</td>\n",
       "      <td>{'region': 'Teruel'}</td>\n",
       "      <td>region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quiero ver todas las licitaciones de Girona.</td>\n",
       "      <td>SELECT * FROM expedientes JOIN entidades ON ex...</td>\n",
       "      <td>expedientes</td>\n",
       "      <td>{'region': 'Girona'}</td>\n",
       "      <td>region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Solicito información de licitaciones en Soria.</td>\n",
       "      <td>SELECT * FROM expedientes JOIN entidades ON ex...</td>\n",
       "      <td>expedientes</td>\n",
       "      <td>{'region': 'Soria'}</td>\n",
       "      <td>region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>¿Qué contratos existen ahora mismo para la reg...</td>\n",
       "      <td>SELECT * FROM expedientes JOIN entidades ON ex...</td>\n",
       "      <td>expedientes</td>\n",
       "      <td>{'region': 'Comunitat Valenciana'}</td>\n",
       "      <td>region</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Pregunta  \\\n",
       "0  Quiero ver todas las licitaciones de Principad...   \n",
       "1      ¿Qué expedientes están registrados en Teruel?   \n",
       "2       Quiero ver todas las licitaciones de Girona.   \n",
       "3     Solicito información de licitaciones en Soria.   \n",
       "4  ¿Qué contratos existen ahora mismo para la reg...   \n",
       "\n",
       "                                            Consulta        Tabla  \\\n",
       "0  SELECT * FROM expedientes JOIN entidades ON ex...  expedientes   \n",
       "1  SELECT * FROM expedientes JOIN entidades ON ex...  expedientes   \n",
       "2  SELECT * FROM expedientes JOIN entidades ON ex...  expedientes   \n",
       "3  SELECT * FROM expedientes JOIN entidades ON ex...  expedientes   \n",
       "4  SELECT * FROM expedientes JOIN entidades ON ex...  expedientes   \n",
       "\n",
       "                                Valores Categoría  \n",
       "0  {'region': 'Principado de Asturias'}    region  \n",
       "1                  {'region': 'Teruel'}    region  \n",
       "2                  {'region': 'Girona'}    region  \n",
       "3                   {'region': 'Soria'}    region  \n",
       "4    {'region': 'Comunitat Valenciana'}    region  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga del dataset\n",
    "import pandas as pd\n",
    "\n",
    "full_dataset = pd.read_csv(\"datasets/sampled_place_dataset_large.csv\")\n",
    "full_dataset = full_dataset.rename(columns={'Unnamed: 0': 'Indice'})\n",
    "\n",
    "# Ejemplo de visualización\n",
    "full_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Definición del *system prompt*\n",
    "\n",
    "A continuación, se define un *prompt* que el modelo recibirá. El objetivo es que el modelo genere la sintaxis SQL correctamente, respetando los nombres de tabla y campos disponibles en el esquema de la base de datos.\n",
    "\n",
    "Se añade también una función `extraer_query_sql` que, de ser necesario, extrae la consulta final de un texto dado mediante una expresión regular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "Dada una pregunta de entrada, crea una consulta de postgresql sintácticamente correcta.\n",
    "Usa solo los nombres de las columnas que puedes ver en la descripción del esquema.\n",
    "No consultes columnas que no existen.\n",
    "Utiliza únicamente las siguientes tablas: 'entidades', 'expedientes', 'paises', 'regiones'\n",
    "Esquema de la base de datos:\n",
    "{db.table_info}\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "def extraer_query_sql(texto):\n",
    "    patron = re.compile(\n",
    "        r\"SELECT \\*(?:.|\\n)*?;\"\n",
    "    )\n",
    "    consulta = patron.findall(texto)\n",
    "    return consulta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de columnas de instrucciones\n",
    "\n",
    "El *prompt* final se construye concatenando el `system_prompt` con la pregunta y la respuesta esperada (la consulta SQL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reordenar_dataframe_por_categoria(df, col_categoria='Categoría'):\n",
    "    \"\"\"\n",
    "    Reordena el DataFrame 'df' en bloques, de forma que cada bloque de 35 filas\n",
    "    contenga exactamente una fila de cada categoría.\n",
    "    \"\"\"\n",
    "    categorias = df[col_categoria].unique()\n",
    "    \n",
    "    #Comprobar que existan exactamente 35 categorías\n",
    "    if len(categorias) != 35:\n",
    "        raise ValueError(f\"Se esperaban 35 categorías únicas, pero se encontraron {len(categorias)}.\")\n",
    "    \n",
    "    # Agrupar filas por categoría\n",
    "    grupos_por_categoria = {\n",
    "        cat: g.reset_index(drop=True) \n",
    "        for cat, g in df.groupby(col_categoria)\n",
    "    }\n",
    "    # Comprobar que cada categoría tenga 7 filas\n",
    "    for cat, subdf in grupos_por_categoria.items():\n",
    "        if len(subdf) != 63:\n",
    "            raise ValueError(\n",
    "                f\"La categoría '{cat}' no tiene exactamente 69 filas. \"\n",
    "                f\"Encontradas: {len(subdf)}.\"\n",
    "            ) \n",
    "    # Construir el nuevo orden de filas:\n",
    "    nuevo_orden = []\n",
    "    for i in range(63):\n",
    "        for cat in categorias:\n",
    "            # Tomamos la fila i de la categoría cat\n",
    "            fila = grupos_por_categoria[cat].iloc[i]\n",
    "            # Agregamos esa fila a la lista que formará el nuevo DataFrame\n",
    "            nuevo_orden.append(fila)\n",
    "    \n",
    "    # Convertir la lista de filas en DataFrame y reindexar\n",
    "    df_reordenado = pd.DataFrame(nuevo_orden).reset_index(drop=True)\n",
    "    \n",
    "    return df_reordenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dada una pregunta de entrada, crea una consulta de postgresql sintácticamente correcta.\n",
      "Usa solo los nombres de las columnas que puedes ver en la descripción del esquema.\n",
      "No consultes columnas que no existen.\n",
      "Utiliza únicamente las siguientes tablas: 'entidades', 'expedientes', 'paises', 'regiones'\n",
      "Esquema de la base de datos:\n",
      "\n",
      "CREATE TABLE documentos (\n",
      "\tdocument_reference_id VARCHAR, \n",
      "\tdocument_uri VARCHAR NOT NULL, \n",
      "\tdocument_type VARCHAR, \n",
      "\tcontract_id VARCHAR, \n",
      "\tCONSTRAINT documentos_pkey PRIMARY KEY (document_uri), \n",
      "\tCONSTRAINT documentos_contract_id_fkey FOREIGN KEY(contract_id) REFERENCES expedientes (contract_folder_id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from documentos table:\n",
      "document_reference_id\tdocument_uri\tdocument_type\tcontract_id\n",
      "PCAP 50 equipos trabajo en movilidad Anexo I acuerdo MP.pdf\thttps://contrataciondelestado.es/wps/wcm/connect/PLACE_es/Site/area/docAccCmpnt?srv=cmpnt&cmpntname=\tPliego Administrativo\t2023/20\n",
      "PPT Suministro 50 portatiles Anexo II acuerdo MP.pdf\thttps://contrataciondelestado.es/wps/wcm/connect/PLACE_es/Site/area/docAccCmpnt?srv=cmpnt&cmpntname=\tPliego Técnico\t2023/20\n",
      "04 PCAP 35 2023 FIRMADO.pdf\thttps://contrataciondelestado.es/wps/wcm/connect/PLACE_es/Site/area/docAccCmpnt?srv=cmpnt&cmpntname=\tPliego Administrativo\tCON 35/2023 SE AB\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE entidades (\n",
      "\tnif VARCHAR NOT NULL, \n",
      "\tname VARCHAR, \n",
      "\twebsite_uri VARCHAR, \n",
      "\ttype_code VARCHAR, \n",
      "\tactivity_code VARCHAR, \n",
      "\tparty_subentity_code VARCHAR, \n",
      "\tparty_postal_zone VARCHAR, \n",
      "\tparty_address_line VARCHAR, \n",
      "\ttelephone VARCHAR, \n",
      "\ttelefax VARCHAR, \n",
      "\temail VARCHAR, \n",
      "\tdir3 VARCHAR, \n",
      "\tid_plataforma VARCHAR, \n",
      "\tCONSTRAINT entidades_pkey PRIMARY KEY (nif), \n",
      "\tCONSTRAINT entidades_party_subentity_code_fkey FOREIGN KEY(party_subentity_code) REFERENCES regiones (country_subentity_code)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from entidades table:\n",
      "nif\tname\twebsite_uri\ttype_code\tactivity_code\tparty_subentity_code\tparty_postal_zone\tparty_address_line\ttelephone\ttelefax\temail\tdir3\tid_plataforma\n",
      "S4133001J\tParlamento de Andalucía\thttp://www.parlamentodeandalucia.es\t2\t1\tES618\t41009\tc/ San Juan de Ribera s/n\t954592100\t954592248\tcontratacion@parlamentodeandalucia.es\tI00000175\t20015840002647\n",
      "P2801300A\tJunta de Gobierno del Ayuntamiento de Aranjuez\tNone\t3\t1\tES3\t28300\tPlaza de la Constitución s/n\t918090360\t918925714\tnotificaciones.contratacion@aranjuez.es\tL01280133\t11021420145902\n",
      "Q2802152E\tADIF Alta Velocidad - Consejo de Administración\thttp://www.adifaltavelocidad.es\t6\t1\tES514\t28020\tSor Ángela de la Cruz, 3\t917674390\tNone\tcomprascontratacion@adif.es\tEA0008223\t40515810090801\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE expedientes (\n",
      "\tcontract_folder_id VARCHAR NOT NULL, \n",
      "\tentry_id VARCHAR, \n",
      "\tlink VARCHAR, \n",
      "\tsummary VARCHAR, \n",
      "\ttitle VARCHAR, \n",
      "\tupdated VARCHAR, \n",
      "\tcontract_folder_status VARCHAR, \n",
      "\tprocurement_project_type_code VARCHAR, \n",
      "\tprocurement_project_subtype_name VARCHAR, \n",
      "\tbudget_currency VARCHAR, \n",
      "\testimated_overall_contract_amount NUMERIC(12, 2), \n",
      "\ttotal_amount NUMERIC(12, 2), \n",
      "\ttax_exclusive_amount NUMERIC(12, 2), \n",
      "\tparty_nif VARCHAR, \n",
      "\tCONSTRAINT expedientes_pkey PRIMARY KEY (contract_folder_id), \n",
      "\tCONSTRAINT expedientes_party_nif_fkey FOREIGN KEY(party_nif) REFERENCES entidades (nif)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from expedientes table:\n",
      "contract_folder_id\tentry_id\tlink\tsummary\ttitle\tupdated\tcontract_folder_status\tprocurement_project_type_code\tprocurement_project_subtype_name\tbudget_currency\testimated_overall_contract_amount\ttotal_amount\ttax_exclusive_amount\tparty_nif\n",
      "2023/20\thttps://contrataciondelestado.es/sindicacion/licitacionesPerfilContratante/13983936\thttps://contrataciondelestado.es/wps/poc?uri=deeplink:detalle_licitacion&idEvl=Ag4n4m84LtCqb7rCcv76B\tId licitación: 2023/20; Órgano de Contratación: Parlamento de Andalucía; Importe: 99750 EUR; Estado:\tSuministro de equipamiento para el trabajo de trabajo en movilidad del Parlamento de Andalucía.\t2024-01-31T12:59:50.514+01:00\tEn evaluación\tSuministros\tAdquisición\tEUR\t119700.00\t120697.50\t99750.00\tS4133001J\n",
      "CON 35/2023 SE AB\thttps://contrataciondelestado.es/sindicacion/licitacionesPerfilContratante/13689210\thttps://contrataciondelestado.es/wps/poc?uri=deeplink:detalle_licitacion&idEvl=5890HdUK6hTCfVQHDepjG\tId licitación: CON 35/2023 SE AB; Órgano de Contratación: Junta de Gobierno del Ayuntamiento de Aran\tContrato del servicio de mantenimiento de los sistemas de bombeo de aguas fecales y pluviales existe\t2024-01-31T12:59:45.080+01:00\tEn evaluación\tServicios\tServicios de mantenimiento y reparación\tEUR\t234166.54\t184787.94\t152717.31\tP2801300A\n",
      "3.23/20830.0084\thttps://contrataciondelestado.es/sindicacion/licitacionesPerfilContratante/13027573\thttps://contrataciondelestado.es/wps/poc?uri=deeplink:detalle_licitacion&idEvl=niS3E86NfhYadbH3CysQu\tId licitación: 3.23/20830.0084; Órgano de Contratación: ADIF Alta Velocidad - Consejo de Administrac\tEjecución de las obras del proyecto de construcción de las actuaciones derivadas del estudio sobre e\t2024-01-31T12:59:41.600+01:00\tAdjudicado\tObras\tNone\tEUR\t5260595.01\t6365319.96\t5260595.01\tQ2802152E\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE paises (\n",
      "\tcountry_code VARCHAR NOT NULL, \n",
      "\tcountry_name VARCHAR, \n",
      "\tCONSTRAINT paises_pkey PRIMARY KEY (country_code)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from paises table:\n",
      "country_code\tcountry_name\n",
      "1A\tKosovo\n",
      "AT\tAustria\n",
      "BE\tBélgica\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE regiones (\n",
      "\tcountry_subentity_code VARCHAR NOT NULL, \n",
      "\tcountry_subentity_name VARCHAR, \n",
      "\tcountry_code VARCHAR, \n",
      "\tCONSTRAINT regiones_pkey PRIMARY KEY (country_subentity_code), \n",
      "\tCONSTRAINT regiones_country_code_fkey FOREIGN KEY(country_code) REFERENCES paises (country_code)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from regiones table:\n",
      "country_subentity_code\tcountry_subentity_name\tcountry_code\n",
      "AT\tÖsterreich\tAT\n",
      "AT1\tOstösterreich\tAT\n",
      "AT11\tBurgenland\tAT\n",
      "*/\n",
      " Pregunta: ¿Cuáles son los expedientes en la región de Sur? Comienza la query siempre por SELECT * y termínala siempre por ; Respuesta: SELECT * FROM expedientes JOIN entidades ON expedientes.party_nif = entidades.nif JOIN regiones ON entidades.party_subentity_code = regiones.country_subentity_code WHERE regiones.country_subentity_name = 'Sur';\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rodrigo\\AppData\\Local\\Temp\\ipykernel_8132\\1506364510.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[\"Instrucciones\"] = system_prompt + \" Pregunta: \" + train_df[\"Pregunta\"] + \" Comienza la query siempre por SELECT * y termínala siempre por ; Respuesta: \" + train_df[\"Consulta\"]\n",
      "C:\\Users\\Rodrigo\\AppData\\Local\\Temp\\ipykernel_8132\\1506364510.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eval_df[\"Instrucciones\"] = system_prompt + \" Pregunta: \" + eval_df[\"Pregunta\"] + \" Comienza la query siempre por SELECT * y termínala siempre por ; Respuesta: \" + eval_df[\"Consulta\"]\n"
     ]
    }
   ],
   "source": [
    "dataset_ordenado = reordenar_dataframe_por_categoria(full_dataset)\n",
    "\n",
    "train_df = dataset_ordenado.iloc[:1680]  # 1680 elementos\n",
    "eval_df = dataset_ordenado.iloc[1680:2030]    # 350 elementos\n",
    "\n",
    "train_df[\"Instrucciones\"] = system_prompt + \" Pregunta: \" + train_df[\"Pregunta\"] + \" Comienza la query siempre por SELECT * y termínala siempre por ; Respuesta: \" + train_df[\"Consulta\"]\n",
    "eval_df[\"Instrucciones\"] = system_prompt + \" Pregunta: \" + eval_df[\"Pregunta\"] + \" Comienza la query siempre por SELECT * y termínala siempre por ; Respuesta: \" + eval_df[\"Consulta\"]\n",
    "\n",
    "# Ejemplo de impresión de las instrucciones\n",
    "print(eval_df[\"Instrucciones\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tokenización del dataset\n",
    "\n",
    "En la siguiente sección, se transforma el texto (las instrucciones) en vectores de *tokens*, usando el *tokenizer* correspondiente al modelo base. Además, se ajustan parámetros de tokenización como:\n",
    "\n",
    "- `max_length`: la longitud máxima de tokens en cada ejemplo.\n",
    "- `truncation`: para que se recorte si excede el máximo.\n",
    "- `return_tensors=None`: para mantener la estructura que pide la librería.\n",
    "- Se asignan las etiquetas (`labels`) como copia de `input_ids`, ya que es un entrenamiento de lenguaje causal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rodrigo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Map: 100%|██████████| 1680/1680 [00:10<00:00, 157.64 examples/s]\n",
      "Map: 100%|██████████| 350/350 [00:02<00:00, 159.79 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "eval_ds = Dataset.from_pandas(eval_df)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"deepseek-ai/deepseek-coder-1.3b-base\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "def tokenize(data_point):\n",
    "    result = tokenizer(\n",
    "        data_point['Instrucciones'],\n",
    "        truncation=True,\n",
    "        max_length=2256,\n",
    "        return_tensors=None,\n",
    "    ).to(\"cuda\")\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "train_tokenized = train_ds.map(tokenize)\n",
    "eval_tokenized = eval_ds.map(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Definición del modelo y configuración LoRA\n",
    "\n",
    "Se define la función `model_init()` que:\n",
    "1. Carga el modelo base `deepseek-ai/deepseek-coder-1.3b-base` con cuantización en 8 bits.\n",
    "2. Desactiva `use_cache`.\n",
    "3. Prepara el modelo para entrenamiento k-bit (`prepare_model_for_kbit_training`).\n",
    "4. Aplica el método *LoRA* (PEFT) para entrenar solo algunos de los parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    DataCollatorForSeq2Seq, \n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    BitsAndBytesConfig,\n",
    "    AutoModelForCausalLM\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    TaskType,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "def model_init():\n",
    "    model_name = \"deepseek-ai/deepseek-coder-1.3b-base\"\n",
    "    bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "    \n",
    "    # Cargar el modelo base con cuantización en 8 bits\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        quantization_config=bnb_config\n",
    "    )\n",
    "    \n",
    "    model.config.use_cache = False\n",
    "    \n",
    "    # Preparar el modelo para entrenamiento k-bit\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    \n",
    "    # Definir la configuración de LoRA\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        inference_mode=False,\n",
    "        r=4,\n",
    "        lora_alpha=64,\n",
    "        lora_dropout=0.1,\n",
    "        target_modules=[\"q_proj\", \"v_proj\"]\n",
    "    )\n",
    "    \n",
    "    # Aplicar LoRA al modelo\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Búsqueda de hiperparámetros (Grid / Random Search)\n",
    "\n",
    "En la siguiente celda se muestra un ejemplo de búsqueda de hiperparámetros donde se prueban varias combinaciones de:\n",
    "\n",
    "- `learning_rates`\n",
    "- `batch_sizes`\n",
    "- `num_epochs`\n",
    "- `gradient_steps`\n",
    "\n",
    "Después, se realiza un *training* y evaluación con cada combinación para encontrar la mejor configuración.\n",
    "\n",
    "> *Nota:* Es posible que esta sección tome tiempo significativo al ejecutarse, dependiendo de la capacidad de cómputo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prueba 1: lr=0.0005, batch_size=2, epochs=3, grad_steps=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rodrigo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrodrigo-gonzalez-pulido\u001b[0m (\u001b[33mrodrigo-gonzalez-pulido-universidad-aut-noma-de-madrid\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Rodrigo\\Documents\\TFM\\place-rag-backend\\wandb\\run-20250130_203640-3lypidqd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rodrigo-gonzalez-pulido-universidad-aut-noma-de-madrid/huggingface/runs/3lypidqd' target=\"_blank\">deepseek-coder-1.3b-base-2025-01-30-20-36-34</a></strong> to <a href='https://wandb.ai/rodrigo-gonzalez-pulido-universidad-aut-noma-de-madrid/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rodrigo-gonzalez-pulido-universidad-aut-noma-de-madrid/huggingface' target=\"_blank\">https://wandb.ai/rodrigo-gonzalez-pulido-universidad-aut-noma-de-madrid/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rodrigo-gonzalez-pulido-universidad-aut-noma-de-madrid/huggingface/runs/3lypidqd' target=\"_blank\">https://wandb.ai/rodrigo-gonzalez-pulido-universidad-aut-noma-de-madrid/huggingface/runs/3lypidqd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rodrigo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\Rodrigo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\bitsandbytes\\autograd\\_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='264' max='264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [264/264 23:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.941000</td>\n",
       "      <td>0.451502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.235700</td>\n",
       "      <td>0.089987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.010881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.001431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.001058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.000958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: {'eval_loss': 0.00013899854093324393, 'eval_runtime': 18.5299, 'eval_samples_per_second': 1.889, 'eval_steps_per_second': 0.27, 'epoch': 3.0}\n",
      "Prueba 2: lr=1e-05, batch_size=4, epochs=3, grad_steps=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rodrigo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 15:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.292800</td>\n",
       "      <td>1.284956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.280300</td>\n",
       "      <td>1.277062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.272900</td>\n",
       "      <td>1.270911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:25]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: {'eval_loss': 1.2702876329421997, 'eval_runtime': 32.0598, 'eval_samples_per_second': 1.092, 'eval_steps_per_second': 0.156, 'epoch': 3.0}\n",
      "Prueba 3: lr=1e-05, batch_size=2, epochs=3, grad_steps=2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 16:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.292800</td>\n",
       "      <td>1.283032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.276900</td>\n",
       "      <td>1.268428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.262600</td>\n",
       "      <td>1.257502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.248800</td>\n",
       "      <td>1.241922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.235400</td>\n",
       "      <td>1.227177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.222400</td>\n",
       "      <td>1.218079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.210700</td>\n",
       "      <td>1.205883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.199300</td>\n",
       "      <td>1.195691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.189400</td>\n",
       "      <td>1.184501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.180600</td>\n",
       "      <td>1.177750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.173800</td>\n",
       "      <td>1.171860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.168900</td>\n",
       "      <td>1.166217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.166200</td>\n",
       "      <td>1.166735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: {'eval_loss': 1.165602684020996, 'eval_runtime': 17.3807, 'eval_samples_per_second': 2.014, 'eval_steps_per_second': 0.288, 'epoch': 3.0}\n",
      "Prueba 4: lr=0.001, batch_size=8, epochs=7, grad_steps=4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 4:05:26, Epoch 5/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.206476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>0.015538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.001859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: {'eval_loss': 0.0016281469725072384, 'eval_runtime': 20.9302, 'eval_samples_per_second': 1.672, 'eval_steps_per_second': 0.239, 'epoch': 5.909090909090909}\n",
      "Prueba 5: lr=0.0001, batch_size=8, epochs=3, grad_steps=4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 1:39:19, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.241900</td>\n",
       "      <td>1.188464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: {'eval_loss': 1.168552279472351, 'eval_runtime': 18.5396, 'eval_samples_per_second': 1.888, 'eval_steps_per_second': 0.27, 'epoch': 2.5454545454545454}\n",
      "Prueba 6: lr=5e-05, batch_size=4, epochs=3, grad_steps=1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 19:51, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.265200</td>\n",
       "      <td>1.224209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.185400</td>\n",
       "      <td>1.136633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.089000</td>\n",
       "      <td>1.029133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.969600</td>\n",
       "      <td>0.893556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.817900</td>\n",
       "      <td>0.722118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.645400</td>\n",
       "      <td>0.552513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.486700</td>\n",
       "      <td>0.408044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.357300</td>\n",
       "      <td>0.297006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.263300</td>\n",
       "      <td>0.221951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.197400</td>\n",
       "      <td>0.168752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.153500</td>\n",
       "      <td>0.135312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.125100</td>\n",
       "      <td>0.112844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.110200</td>\n",
       "      <td>0.104081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: {'eval_loss': 0.10392394661903381, 'eval_runtime': 27.3433, 'eval_samples_per_second': 1.28, 'eval_steps_per_second': 0.183, 'epoch': 3.0}\n",
      "Prueba 7: lr=0.001, batch_size=4, epochs=3, grad_steps=2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 19:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.750100</td>\n",
       "      <td>0.203085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.095600</td>\n",
       "      <td>0.015497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.001592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.001001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: {'eval_loss': 0.000716207199729979, 'eval_runtime': 33.0473, 'eval_samples_per_second': 1.059, 'eval_steps_per_second': 0.151, 'epoch': 3.0}\n",
      "Prueba 8: lr=1e-05, batch_size=2, epochs=5, grad_steps=2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='220' max='220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [220/220 27:06, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.292400</td>\n",
       "      <td>1.284037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.276600</td>\n",
       "      <td>1.271344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.261200</td>\n",
       "      <td>1.252926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.245400</td>\n",
       "      <td>1.238630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.229400</td>\n",
       "      <td>1.222125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.213300</td>\n",
       "      <td>1.203915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.196500</td>\n",
       "      <td>1.186942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.178800</td>\n",
       "      <td>1.169181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.161200</td>\n",
       "      <td>1.152619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.143200</td>\n",
       "      <td>1.133582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.125500</td>\n",
       "      <td>1.115457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.109000</td>\n",
       "      <td>1.099819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.091400</td>\n",
       "      <td>1.082571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.075500</td>\n",
       "      <td>1.067544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.059900</td>\n",
       "      <td>1.052676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.045700</td>\n",
       "      <td>1.040355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.032700</td>\n",
       "      <td>1.027310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.022100</td>\n",
       "      <td>1.014973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.013300</td>\n",
       "      <td>1.009677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.006300</td>\n",
       "      <td>1.002498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.000900</td>\n",
       "      <td>0.999220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>0.997186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: {'eval_loss': 0.9971861839294434, 'eval_runtime': 17.6145, 'eval_samples_per_second': 1.987, 'eval_steps_per_second': 0.284, 'epoch': 5.0}\n",
      "Prueba 9: lr=1e-05, batch_size=8, epochs=5, grad_steps=1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 3:30:10, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.292700</td>\n",
       "      <td>1.285448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.276800</td>\n",
       "      <td>1.268563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.263000</td>\n",
       "      <td>1.255463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.249900</td>\n",
       "      <td>1.243590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.237600</td>\n",
       "      <td>1.232252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.226400</td>\n",
       "      <td>1.221224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.216400</td>\n",
       "      <td>1.212377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.208000</td>\n",
       "      <td>1.204660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.201400</td>\n",
       "      <td>1.198533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.196800</td>\n",
       "      <td>1.194547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.194500</td>\n",
       "      <td>1.194080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: {'eval_loss': 1.194079875946045, 'eval_runtime': 20.8887, 'eval_samples_per_second': 1.676, 'eval_steps_per_second': 0.239, 'epoch': 5.0}\n",
      "Prueba 10: lr=1e-05, batch_size=8, epochs=3, grad_steps=2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 3:36:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.293400</td>\n",
       "      <td>1.287669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.281600</td>\n",
       "      <td>1.278562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.274500</td>\n",
       "      <td>1.272990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 08:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: {'eval_loss': 1.2739086151123047, 'eval_runtime': 652.8946, 'eval_samples_per_second': 0.054, 'eval_steps_per_second': 0.008, 'epoch': 3.0}\n",
      "Prueba 11: lr=0.001, batch_size=8, epochs=3, grad_steps=2\n",
      "Prueba 12: lr=0.0001, batch_size=8, epochs=3, grad_steps=1\n",
      "Prueba 13: lr=1e-05, batch_size=8, epochs=7, grad_steps=1\n",
      "Prueba 14: lr=1e-05, batch_size=4, epochs=7, grad_steps=2\n",
      "Prueba 15: lr=0.0001, batch_size=8, epochs=7, grad_steps=4\n",
      "Prueba 16: lr=0.0005, batch_size=2, epochs=5, grad_steps=1\n",
      "Prueba 17: lr=1e-05, batch_size=2, epochs=3, grad_steps=4\n",
      "Prueba 18: lr=0.0001, batch_size=8, epochs=7, grad_steps=2\n",
      "Prueba 19: lr=0.0005, batch_size=2, epochs=7, grad_steps=4\n",
      "Prueba 20: lr=0.0001, batch_size=2, epochs=7, grad_steps=2\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import random\n",
    "from datetime import datetime\n",
    "import torch\n",
    "\n",
    "# Define los rangos de hiperparámetros\n",
    "learning_rates = [1e-5, 5e-5, 1e-4, 5e-4, 1e-3]\n",
    "batch_sizes = [2, 4, 8]\n",
    "num_epochs = [3, 5, 7]\n",
    "gradient_steps = [1, 2, 4]\n",
    "\n",
    "# Genera combinaciones aleatorias\n",
    "combinations = list(itertools.product(learning_rates, batch_sizes, num_epochs, gradient_steps))\n",
    "random.shuffle(combinations)\n",
    "\n",
    "# Limita el número de combinaciones a probar\n",
    "max_trials = 10\n",
    "train_results = []\n",
    "for i, (lr, bs, epochs, gs) in enumerate(combinations[:max_trials]):\n",
    "    try:\n",
    "        print(f\"Prueba {i+1}: lr={lr}, batch_size={bs}, epochs={epochs}, grad_steps={gs}\")\n",
    "        training_arguments = TrainingArguments(\n",
    "            run_name=f\"\"\"deepseek-coder-1.3b-base-{datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")}\"\"\",\n",
    "            output_dir=\"logs\",\n",
    "            num_train_epochs=epochs,\n",
    "            per_device_train_batch_size=bs,\n",
    "            gradient_accumulation_steps=gs,\n",
    "            optim=\"paged_adamw_32bit\",\n",
    "            save_steps=0,\n",
    "            logging_steps=10,\n",
    "            learning_rate=lr,\n",
    "            fp16=True,\n",
    "            bf16=False,\n",
    "            group_by_length=True,\n",
    "            logging_strategy=\"steps\",\n",
    "            evaluation_strategy='steps',\n",
    "            eval_steps=10,\n",
    "            save_strategy=\"no\",\n",
    "            gradient_checkpointing=False,\n",
    "        )\n",
    "        model = model_init()\n",
    "        trainer = Trainer(\n",
    "            model = model,\n",
    "            args=training_arguments,\n",
    "            train_dataset=train_tokenized,\n",
    "            eval_dataset=eval_tokenized,\n",
    "            data_collator=DataCollatorForSeq2Seq(\n",
    "                tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    "            )\n",
    "        )\n",
    "        trainer.train()\n",
    "        eval_results = trainer.evaluate()\n",
    "        train_results.append(eval_results)\n",
    "        print(f\"Resultados: {eval_results}\")\n",
    "        del model # eliminamos el modelo para evitar sobrecarga de memoria\n",
    "        torch.cuda.empty_cache() # limpiamos la cache para evitar sobrecarga de memoria\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # Aquí puedes guardar los resultados y comparar posteriormente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. *Fine-Tuning* Final\n",
    "\n",
    "En la sección anterior se probó con diferentes hiperparámetros, observando la evolución de la *loss* de entrenamiento y validación. Aquí, realizaremos el **entrenamientos final** con una configuración concreta.\n",
    "\n",
    "### Fine-Tuning 1\n",
    "- `learning_rate = 0.0005`\n",
    "- `batch_size = 2`\n",
    "- `num_epochs = 3`\n",
    "- `gradient_accumulation_steps = 1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Fine-Tuning 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rodrigo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Entrenando con Fine-Tuning 1 ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rodrigo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\Rodrigo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\bitsandbytes\\autograd\\_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='2520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  80/2520 2:30:53 < 78:40:17, 0.01 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.941300</td>\n",
       "      <td>0.437795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>0.064055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.028200</td>\n",
       "      <td>0.004631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.003525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.001576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.001036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.002234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deteniendo entrenamiento: eval_loss < 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 17:56]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deteniendo entrenamiento: eval_loss < 0.001\n",
      "Resultados Fine-Tuning 1: {'eval_loss': 0.0007878464530222118, 'eval_runtime': 1100.6203, 'eval_samples_per_second': 0.318, 'eval_steps_per_second': 0.04, 'epoch': 0.09523809523809523}\n",
      "\n",
      "Modelo Fine-Tuning 1 guardado en: models/deepseek-coder-ft1-2025-02-02-20-12-35\n",
      "Tokenizer guardado en: models/tokenizer-deepseek-coder-ft1-2025-02-02-20-12-36\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from transformers import TrainingArguments, TrainerCallback, Trainer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "# Callback para detener el entrenamiento cuando eval_loss < 0.001\n",
    "class EarlyStoppingBelowThresholdCallback(TrainerCallback):\n",
    "    def __init__(self, threshold=0.001):\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        eval_loss = kwargs[\"metrics\"].get(\"eval_loss\")\n",
    "        if eval_loss is not None and eval_loss < self.threshold:\n",
    "            print(f\"Deteniendo entrenamiento: eval_loss < {self.threshold}\")\n",
    "            control.should_training_stop = True\n",
    "\n",
    "learning_rate_1 = 0.0005\n",
    "batch_size_1 = 2\n",
    "num_epochs_1 = 3\n",
    "gradient_steps_1 = 1\n",
    "\n",
    "# Configurar argumentos de entrenamiento\n",
    "training_arguments_1 = TrainingArguments(\n",
    "    run_name=f\"deepseek-coder-1.3b-base-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\",\n",
    "    output_dir=\"logs\",\n",
    "    num_train_epochs=num_epochs_1,\n",
    "    per_device_train_batch_size=batch_size_1,\n",
    "    gradient_accumulation_steps=gradient_steps_1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=0,\n",
    "    logging_steps=10,\n",
    "    learning_rate=learning_rate_1,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    group_by_length=True,\n",
    "    logging_strategy=\"steps\",\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=10,\n",
    "    save_strategy=\"no\",\n",
    "    gradient_checkpointing=False,\n",
    ")\n",
    "\n",
    "# Inicializamos el modelo con LoRA\n",
    "model_1 = model_init()\n",
    "\n",
    "# Definimos el Trainer\n",
    "trainer_1 = Trainer(\n",
    "    model = model_1,\n",
    "    args=training_arguments_1,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=eval_tokenized,\n",
    "    data_collator=DataCollatorForSeq2Seq(\n",
    "        tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    "    ),\n",
    "    # Agregar el callback de early stopping\n",
    "    callbacks=[EarlyStoppingBelowThresholdCallback(threshold=0.001)],\n",
    ")\n",
    "\n",
    "print(\"\\n--- Entrenando con Fine-Tuning 1 ---\\n\")\n",
    "# Entrenamos\n",
    "trainer_1.train()\n",
    "\n",
    "# Evaluamos\n",
    "eval_results_1 = trainer_1.evaluate()\n",
    "print(f\"Resultados Fine-Tuning: {eval_results_1}\")\n",
    "\n",
    "# Guardamos el modelo y el tokenizer\n",
    "model_1_path = f\"models/deepseek-coder-ft-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "trainer_1.save_model(model_1_path)\n",
    "tokenizer_1_path = f\"models/tokenizer-deepseek-coder-ft-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "tokenizer.save_pretrained(tokenizer_1_path)\n",
    "\n",
    "print(f\"\\nModelo Fine-Tuning 1 guardado en: {model_1_path}\")\n",
    "print(f\"Tokenizer guardado en: {tokenizer_1_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
