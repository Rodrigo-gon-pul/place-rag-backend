{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning de modelo Deepseek Coder con LoRA y 8-bit\n",
    "\n",
    "Este documento describe un proceso para ajustar finamente (*fine-tune*) un modelo de lenguaje (basado en la arquitectura *deepseek-coder-1.3b-base*) para la generaci贸n de consultas SQL, usando:\n",
    "\n",
    "- **LoRA (Low-Rank Adaptation)** para reducir la cantidad de par谩metros a entrenar.\n",
    "- **Quantizaci贸n en 8 bits** a trav茅s de *BitsAndBytes* (`bnb_config`), para reducir la huella de memoria y hacer factible el entrenamiento en GPU.\n",
    "\n",
    "A continuaci贸n, se describen los pasos para:\n",
    "1. Conectar a la base de datos y obtener su esquema.\n",
    "2. Cargar y preparar un *dataset*.\n",
    "3. Definir un *prompt* con indicaciones claras para la tarea de generaci贸n de consultas SQL.\n",
    "4. Entrenar el modelo realizando una b煤squeda de hiperpar谩metros.\n",
    "5. Realizar **dos** *fine-tunings finales* con configuraciones seleccionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conexi贸n con base de datos\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "usuario = 'postgres'\n",
    "password = 'place_rag_password'\n",
    "host = 'localhost'     # o la IP/URL de tu servidor\n",
    "puerto = '5432'        # puerto por defecto de PostgreSQL\n",
    "base_datos = 'place_rag_db'\n",
    "\n",
    "# Crear la URL de conexi贸n\n",
    "uri = f\"postgresql+psycopg2://{usuario}:{password}@{host}:{puerto}/{base_datos}\"\n",
    "\n",
    "# Se instancia la clase SQLDatabase a partir de la URI\n",
    "db = SQLDatabase.from_uri(uri)\n",
    "\n",
    "import os\n",
    "# Cargamos la API key de HF desde las variables de entorno\n",
    "api_key= os.environ.get(\"HF_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y preparaci贸n del *dataset*\n",
    "\n",
    "Se carga un archivo CSV de ejemplo (`sampled_place_dataset.csv`) que contiene pares de \"Pregunta\" y \"Consulta\" (SQL) que se usar谩n en el entrenamiento y la evaluaci贸n del modelo. Posteriormente, se renombran columnas seg煤n la necesidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregunta</th>\n",
       "      <th>Consulta</th>\n",
       "      <th>Tabla</th>\n",
       "      <th>Valores</th>\n",
       "      <th>Categor铆a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quiero ver todas las licitaciones de Principad...</td>\n",
       "      <td>SELECT * FROM expedientes JOIN entidades ON ex...</td>\n",
       "      <td>expedientes</td>\n",
       "      <td>{'region': 'Principado de Asturias'}</td>\n",
       "      <td>region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>驴Qu茅 expedientes est谩n registrados en Teruel?</td>\n",
       "      <td>SELECT * FROM expedientes JOIN entidades ON ex...</td>\n",
       "      <td>expedientes</td>\n",
       "      <td>{'region': 'Teruel'}</td>\n",
       "      <td>region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quiero ver todas las licitaciones de Girona.</td>\n",
       "      <td>SELECT * FROM expedientes JOIN entidades ON ex...</td>\n",
       "      <td>expedientes</td>\n",
       "      <td>{'region': 'Girona'}</td>\n",
       "      <td>region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Solicito informaci贸n de licitaciones en Soria.</td>\n",
       "      <td>SELECT * FROM expedientes JOIN entidades ON ex...</td>\n",
       "      <td>expedientes</td>\n",
       "      <td>{'region': 'Soria'}</td>\n",
       "      <td>region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>驴Qu茅 contratos existen ahora mismo para la reg...</td>\n",
       "      <td>SELECT * FROM expedientes JOIN entidades ON ex...</td>\n",
       "      <td>expedientes</td>\n",
       "      <td>{'region': 'Comunitat Valenciana'}</td>\n",
       "      <td>region</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Pregunta  \\\n",
       "0  Quiero ver todas las licitaciones de Principad...   \n",
       "1      驴Qu茅 expedientes est谩n registrados en Teruel?   \n",
       "2       Quiero ver todas las licitaciones de Girona.   \n",
       "3     Solicito informaci贸n de licitaciones en Soria.   \n",
       "4  驴Qu茅 contratos existen ahora mismo para la reg...   \n",
       "\n",
       "                                            Consulta        Tabla  \\\n",
       "0  SELECT * FROM expedientes JOIN entidades ON ex...  expedientes   \n",
       "1  SELECT * FROM expedientes JOIN entidades ON ex...  expedientes   \n",
       "2  SELECT * FROM expedientes JOIN entidades ON ex...  expedientes   \n",
       "3  SELECT * FROM expedientes JOIN entidades ON ex...  expedientes   \n",
       "4  SELECT * FROM expedientes JOIN entidades ON ex...  expedientes   \n",
       "\n",
       "                                Valores Categor铆a  \n",
       "0  {'region': 'Principado de Asturias'}    region  \n",
       "1                  {'region': 'Teruel'}    region  \n",
       "2                  {'region': 'Girona'}    region  \n",
       "3                   {'region': 'Soria'}    region  \n",
       "4    {'region': 'Comunitat Valenciana'}    region  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga del dataset\n",
    "import pandas as pd\n",
    "\n",
    "full_dataset = pd.read_csv(\"datasets/sampled_place_dataset_large.csv\")\n",
    "full_dataset = full_dataset.rename(columns={'Unnamed: 0': 'Indice'})\n",
    "\n",
    "# Ejemplo de visualizaci贸n\n",
    "full_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Definici贸n del *system prompt*\n",
    "\n",
    "A continuaci贸n, se define un *prompt* que el modelo recibir谩. El objetivo es que el modelo genere la sintaxis SQL correctamente, respetando los nombres de tabla y campos disponibles en el esquema de la base de datos.\n",
    "\n",
    "Se a帽ade tambi茅n una funci贸n `extraer_query_sql` que, de ser necesario, extrae la consulta final de un texto dado mediante una expresi贸n regular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "Dada una pregunta de entrada, crea una consulta de postgresql sint谩cticamente correcta.\n",
    "Usa solo los nombres de las columnas que puedes ver en la descripci贸n del esquema.\n",
    "No consultes columnas que no existen.\n",
    "Utiliza 煤nicamente las siguientes tablas: 'entidades', 'expedientes', 'paises', 'regiones'\n",
    "Esquema de la base de datos:\n",
    "{db.table_info}\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "def extraer_query_sql(texto):\n",
    "    patron = re.compile(\n",
    "        r\"SELECT \\*(?:.|\\n)*?;\"\n",
    "    )\n",
    "    consulta = patron.findall(texto)\n",
    "    return consulta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creaci贸n de columnas de instrucciones\n",
    "\n",
    "El *prompt* final se construye concatenando el `system_prompt` con la pregunta y la respuesta esperada (la consulta SQL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reordenar_dataframe_por_categoria(df, col_categoria='Categor铆a'):\n",
    "    \"\"\"\n",
    "    Reordena el DataFrame 'df' en bloques, de forma que cada bloque de 35 filas\n",
    "    contenga exactamente una fila de cada categor铆a.\n",
    "    \"\"\"\n",
    "    categorias = df[col_categoria].unique()\n",
    "    \n",
    "    #Comprobar que existan exactamente 35 categor铆as\n",
    "    if len(categorias) != 35:\n",
    "        raise ValueError(f\"Se esperaban 35 categor铆as 煤nicas, pero se encontraron {len(categorias)}.\")\n",
    "    \n",
    "    # Agrupar filas por categor铆a\n",
    "    grupos_por_categoria = {\n",
    "        cat: g.reset_index(drop=True) \n",
    "        for cat, g in df.groupby(col_categoria)\n",
    "    }\n",
    "    # Comprobar que cada categor铆a tenga 7 filas\n",
    "    for cat, subdf in grupos_por_categoria.items():\n",
    "        if len(subdf) != 63:\n",
    "            raise ValueError(\n",
    "                f\"La categor铆a '{cat}' no tiene exactamente 69 filas. \"\n",
    "                f\"Encontradas: {len(subdf)}.\"\n",
    "            ) \n",
    "    # Construir el nuevo orden de filas:\n",
    "    nuevo_orden = []\n",
    "    for i in range(63):\n",
    "        for cat in categorias:\n",
    "            # Tomamos la fila i de la categor铆a cat\n",
    "            fila = grupos_por_categoria[cat].iloc[i]\n",
    "            # Agregamos esa fila a la lista que formar谩 el nuevo DataFrame\n",
    "            nuevo_orden.append(fila)\n",
    "    \n",
    "    # Convertir la lista de filas en DataFrame y reindexar\n",
    "    df_reordenado = pd.DataFrame(nuevo_orden).reset_index(drop=True)\n",
    "    \n",
    "    return df_reordenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dada una pregunta de entrada, crea una consulta de postgresql sint谩cticamente correcta.\n",
      "Usa solo los nombres de las columnas que puedes ver en la descripci贸n del esquema.\n",
      "No consultes columnas que no existen.\n",
      "Utiliza 煤nicamente las siguientes tablas: 'entidades', 'expedientes', 'paises', 'regiones'\n",
      "Esquema de la base de datos:\n",
      "\n",
      "CREATE TABLE documentos (\n",
      "\tdocument_reference_id VARCHAR, \n",
      "\tdocument_uri VARCHAR NOT NULL, \n",
      "\tdocument_type VARCHAR, \n",
      "\tcontract_id VARCHAR, \n",
      "\tCONSTRAINT documentos_pkey PRIMARY KEY (document_uri), \n",
      "\tCONSTRAINT documentos_contract_id_fkey FOREIGN KEY(contract_id) REFERENCES expedientes (contract_folder_id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from documentos table:\n",
      "document_reference_id\tdocument_uri\tdocument_type\tcontract_id\n",
      "PCAP 50 equipos trabajo en movilidad Anexo I acuerdo MP.pdf\thttps://contrataciondelestado.es/wps/wcm/connect/PLACE_es/Site/area/docAccCmpnt?srv=cmpnt&cmpntname=\tPliego Administrativo\t2023/20\n",
      "PPT Suministro 50 portatiles Anexo II acuerdo MP.pdf\thttps://contrataciondelestado.es/wps/wcm/connect/PLACE_es/Site/area/docAccCmpnt?srv=cmpnt&cmpntname=\tPliego T茅cnico\t2023/20\n",
      "04 PCAP 35 2023 FIRMADO.pdf\thttps://contrataciondelestado.es/wps/wcm/connect/PLACE_es/Site/area/docAccCmpnt?srv=cmpnt&cmpntname=\tPliego Administrativo\tCON 35/2023 SE AB\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE entidades (\n",
      "\tnif VARCHAR NOT NULL, \n",
      "\tname VARCHAR, \n",
      "\twebsite_uri VARCHAR, \n",
      "\ttype_code VARCHAR, \n",
      "\tactivity_code VARCHAR, \n",
      "\tparty_subentity_code VARCHAR, \n",
      "\tparty_postal_zone VARCHAR, \n",
      "\tparty_address_line VARCHAR, \n",
      "\ttelephone VARCHAR, \n",
      "\ttelefax VARCHAR, \n",
      "\temail VARCHAR, \n",
      "\tdir3 VARCHAR, \n",
      "\tid_plataforma VARCHAR, \n",
      "\tCONSTRAINT entidades_pkey PRIMARY KEY (nif), \n",
      "\tCONSTRAINT entidades_party_subentity_code_fkey FOREIGN KEY(party_subentity_code) REFERENCES regiones (country_subentity_code)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from entidades table:\n",
      "nif\tname\twebsite_uri\ttype_code\tactivity_code\tparty_subentity_code\tparty_postal_zone\tparty_address_line\ttelephone\ttelefax\temail\tdir3\tid_plataforma\n",
      "S4133001J\tParlamento de Andaluc铆a\thttp://www.parlamentodeandalucia.es\t2\t1\tES618\t41009\tc/ San Juan de Ribera s/n\t954592100\t954592248\tcontratacion@parlamentodeandalucia.es\tI00000175\t20015840002647\n",
      "P2801300A\tJunta de Gobierno del Ayuntamiento de Aranjuez\tNone\t3\t1\tES3\t28300\tPlaza de la Constituci贸n s/n\t918090360\t918925714\tnotificaciones.contratacion@aranjuez.es\tL01280133\t11021420145902\n",
      "Q2802152E\tADIF Alta Velocidad - Consejo de Administraci贸n\thttp://www.adifaltavelocidad.es\t6\t1\tES514\t28020\tSor ngela de la Cruz, 3\t917674390\tNone\tcomprascontratacion@adif.es\tEA0008223\t40515810090801\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE expedientes (\n",
      "\tcontract_folder_id VARCHAR NOT NULL, \n",
      "\tentry_id VARCHAR, \n",
      "\tlink VARCHAR, \n",
      "\tsummary VARCHAR, \n",
      "\ttitle VARCHAR, \n",
      "\tupdated VARCHAR, \n",
      "\tcontract_folder_status VARCHAR, \n",
      "\tprocurement_project_type_code VARCHAR, \n",
      "\tprocurement_project_subtype_name VARCHAR, \n",
      "\tbudget_currency VARCHAR, \n",
      "\testimated_overall_contract_amount NUMERIC(12, 2), \n",
      "\ttotal_amount NUMERIC(12, 2), \n",
      "\ttax_exclusive_amount NUMERIC(12, 2), \n",
      "\tparty_nif VARCHAR, \n",
      "\tCONSTRAINT expedientes_pkey PRIMARY KEY (contract_folder_id), \n",
      "\tCONSTRAINT expedientes_party_nif_fkey FOREIGN KEY(party_nif) REFERENCES entidades (nif)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from expedientes table:\n",
      "contract_folder_id\tentry_id\tlink\tsummary\ttitle\tupdated\tcontract_folder_status\tprocurement_project_type_code\tprocurement_project_subtype_name\tbudget_currency\testimated_overall_contract_amount\ttotal_amount\ttax_exclusive_amount\tparty_nif\n",
      "2023/20\thttps://contrataciondelestado.es/sindicacion/licitacionesPerfilContratante/13983936\thttps://contrataciondelestado.es/wps/poc?uri=deeplink:detalle_licitacion&idEvl=Ag4n4m84LtCqb7rCcv76B\tId licitaci贸n: 2023/20; rgano de Contrataci贸n: Parlamento de Andaluc铆a; Importe: 99750 EUR; Estado:\tSuministro de equipamiento para el trabajo de trabajo en movilidad del Parlamento de Andaluc铆a.\t2024-01-31T12:59:50.514+01:00\tEn evaluaci贸n\tSuministros\tAdquisici贸n\tEUR\t119700.00\t120697.50\t99750.00\tS4133001J\n",
      "CON 35/2023 SE AB\thttps://contrataciondelestado.es/sindicacion/licitacionesPerfilContratante/13689210\thttps://contrataciondelestado.es/wps/poc?uri=deeplink:detalle_licitacion&idEvl=5890HdUK6hTCfVQHDepjG\tId licitaci贸n: CON 35/2023 SE AB; rgano de Contrataci贸n: Junta de Gobierno del Ayuntamiento de Aran\tContrato del servicio de mantenimiento de los sistemas de bombeo de aguas fecales y pluviales existe\t2024-01-31T12:59:45.080+01:00\tEn evaluaci贸n\tServicios\tServicios de mantenimiento y reparaci贸n\tEUR\t234166.54\t184787.94\t152717.31\tP2801300A\n",
      "3.23/20830.0084\thttps://contrataciondelestado.es/sindicacion/licitacionesPerfilContratante/13027573\thttps://contrataciondelestado.es/wps/poc?uri=deeplink:detalle_licitacion&idEvl=niS3E86NfhYadbH3CysQu\tId licitaci贸n: 3.23/20830.0084; rgano de Contrataci贸n: ADIF Alta Velocidad - Consejo de Administrac\tEjecuci贸n de las obras del proyecto de construcci贸n de las actuaciones derivadas del estudio sobre e\t2024-01-31T12:59:41.600+01:00\tAdjudicado\tObras\tNone\tEUR\t5260595.01\t6365319.96\t5260595.01\tQ2802152E\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE paises (\n",
      "\tcountry_code VARCHAR NOT NULL, \n",
      "\tcountry_name VARCHAR, \n",
      "\tCONSTRAINT paises_pkey PRIMARY KEY (country_code)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from paises table:\n",
      "country_code\tcountry_name\n",
      "1A\tKosovo\n",
      "AT\tAustria\n",
      "BE\tB茅lgica\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE regiones (\n",
      "\tcountry_subentity_code VARCHAR NOT NULL, \n",
      "\tcountry_subentity_name VARCHAR, \n",
      "\tcountry_code VARCHAR, \n",
      "\tCONSTRAINT regiones_pkey PRIMARY KEY (country_subentity_code), \n",
      "\tCONSTRAINT regiones_country_code_fkey FOREIGN KEY(country_code) REFERENCES paises (country_code)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from regiones table:\n",
      "country_subentity_code\tcountry_subentity_name\tcountry_code\n",
      "AT\tsterreich\tAT\n",
      "AT1\tOst枚sterreich\tAT\n",
      "AT11\tBurgenland\tAT\n",
      "*/\n",
      " Pregunta: 驴Cu谩les son los expedientes en la regi贸n de Sur? Comienza la query siempre por SELECT * y term铆nala siempre por ; Respuesta: SELECT * FROM expedientes JOIN entidades ON expedientes.party_nif = entidades.nif JOIN regiones ON entidades.party_subentity_code = regiones.country_subentity_code WHERE regiones.country_subentity_name = 'Sur';\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rodrigo\\AppData\\Local\\Temp\\ipykernel_8132\\1506364510.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[\"Instrucciones\"] = system_prompt + \" Pregunta: \" + train_df[\"Pregunta\"] + \" Comienza la query siempre por SELECT * y term铆nala siempre por ; Respuesta: \" + train_df[\"Consulta\"]\n",
      "C:\\Users\\Rodrigo\\AppData\\Local\\Temp\\ipykernel_8132\\1506364510.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eval_df[\"Instrucciones\"] = system_prompt + \" Pregunta: \" + eval_df[\"Pregunta\"] + \" Comienza la query siempre por SELECT * y term铆nala siempre por ; Respuesta: \" + eval_df[\"Consulta\"]\n"
     ]
    }
   ],
   "source": [
    "dataset_ordenado = reordenar_dataframe_por_categoria(full_dataset)\n",
    "\n",
    "train_df = dataset_ordenado.iloc[:1680]  # 1680 elementos\n",
    "eval_df = dataset_ordenado.iloc[1680:2030]    # 350 elementos\n",
    "\n",
    "train_df[\"Instrucciones\"] = system_prompt + \" Pregunta: \" + train_df[\"Pregunta\"] + \" Comienza la query siempre por SELECT * y term铆nala siempre por ; Respuesta: \" + train_df[\"Consulta\"]\n",
    "eval_df[\"Instrucciones\"] = system_prompt + \" Pregunta: \" + eval_df[\"Pregunta\"] + \" Comienza la query siempre por SELECT * y term铆nala siempre por ; Respuesta: \" + eval_df[\"Consulta\"]\n",
    "\n",
    "# Ejemplo de impresi贸n de las instrucciones\n",
    "print(eval_df[\"Instrucciones\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tokenizaci贸n del dataset\n",
    "\n",
    "En la siguiente secci贸n, se transforma el texto (las instrucciones) en vectores de *tokens*, usando el *tokenizer* correspondiente al modelo base. Adem谩s, se ajustan par谩metros de tokenizaci贸n como:\n",
    "\n",
    "- `max_length`: la longitud m谩xima de tokens en cada ejemplo.\n",
    "- `truncation`: para que se recorte si excede el m谩ximo.\n",
    "- `return_tensors=None`: para mantener la estructura que pide la librer铆a.\n",
    "- Se asignan las etiquetas (`labels`) como copia de `input_ids`, ya que es un entrenamiento de lenguaje causal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rodrigo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Map: 100%|| 1680/1680 [00:10<00:00, 157.64 examples/s]\n",
      "Map: 100%|| 350/350 [00:02<00:00, 159.79 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "eval_ds = Dataset.from_pandas(eval_df)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"deepseek-ai/deepseek-coder-1.3b-base\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "def tokenize(data_point):\n",
    "    result = tokenizer(\n",
    "        data_point['Instrucciones'],\n",
    "        truncation=True,\n",
    "        max_length=2256,\n",
    "        return_tensors=None,\n",
    "    ).to(\"cuda\")\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "train_tokenized = train_ds.map(tokenize)\n",
    "eval_tokenized = eval_ds.map(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Definici贸n del modelo y configuraci贸n LoRA\n",
    "\n",
    "Se define la funci贸n `model_init()` que:\n",
    "1. Carga el modelo base `deepseek-ai/deepseek-coder-1.3b-base` con cuantizaci贸n en 8 bits.\n",
    "2. Desactiva `use_cache`.\n",
    "3. Prepara el modelo para entrenamiento k-bit (`prepare_model_for_kbit_training`).\n",
    "4. Aplica el m茅todo *LoRA* (PEFT) para entrenar solo algunos de los par谩metros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    DataCollatorForSeq2Seq, \n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    BitsAndBytesConfig,\n",
    "    AutoModelForCausalLM\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    TaskType,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "def model_init():\n",
    "    model_name = \"deepseek-ai/deepseek-coder-1.3b-base\"\n",
    "    bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "    \n",
    "    # Cargar el modelo base con cuantizaci贸n en 8 bits\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        quantization_config=bnb_config\n",
    "    )\n",
    "    \n",
    "    model.config.use_cache = False\n",
    "    \n",
    "    # Preparar el modelo para entrenamiento k-bit\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    \n",
    "    # Definir la configuraci贸n de LoRA\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        inference_mode=False,\n",
    "        r=4,\n",
    "        lora_alpha=64,\n",
    "        lora_dropout=0.1,\n",
    "        target_modules=[\"q_proj\", \"v_proj\"]\n",
    "    )\n",
    "    \n",
    "    # Aplicar LoRA al modelo\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. B煤squeda de hiperpar谩metros (Grid / Random Search)\n",
    "\n",
    "En la siguiente celda se muestra un ejemplo de b煤squeda de hiperpar谩metros donde se prueban varias combinaciones de:\n",
    "\n",
    "- `learning_rates`\n",
    "- `batch_sizes`\n",
    "- `num_epochs`\n",
    "- `gradient_steps`\n",
    "\n",
    "Despu茅s, se realiza un *training* y evaluaci贸n con cada combinaci贸n para encontrar la mejor configuraci贸n.\n",
    "\n",
    "> *Nota:* Es posible que esta secci贸n tome tiempo significativo al ejecutarse, dependiendo de la capacidad de c贸mputo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prueba 1: lr=0.0005, batch_size=2, epochs=3, grad_steps=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rodrigo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrodrigo-gonzalez-pulido\u001b[0m (\u001b[33mrodrigo-gonzalez-pulido-universidad-aut-noma-de-madrid\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Rodrigo\\Documents\\TFM\\place-rag-backend\\wandb\\run-20250130_203640-3lypidqd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rodrigo-gonzalez-pulido-universidad-aut-noma-de-madrid/huggingface/runs/3lypidqd' target=\"_blank\">deepseek-coder-1.3b-base-2025-01-30-20-36-34</a></strong> to <a href='https://wandb.ai/rodrigo-gonzalez-pulido-universidad-aut-noma-de-madrid/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rodrigo-gonzalez-pulido-universidad-aut-noma-de-madrid/huggingface' target=\"_blank\">https://wandb.ai/rodrigo-gonzalez-pulido-universidad-aut-noma-de-madrid/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rodrigo-gonzalez-pulido-universidad-aut-noma-de-madrid/huggingface/runs/3lypidqd' target=\"_blank\">https://wandb.ai/rodrigo-gonzalez-pulido-universidad-aut-noma-de-madrid/huggingface/runs/3lypidqd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rodrigo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\Rodrigo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\bitsandbytes\\autograd\\_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='264' max='264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [264/264 23:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.941000</td>\n",
       "      <td>0.451502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.235700</td>\n",
       "      <td>0.089987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.010881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.001431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.001058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.000958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: {'eval_loss': 0.00013899854093324393, 'eval_runtime': 18.5299, 'eval_samples_per_second': 1.889, 'eval_steps_per_second': 0.27, 'epoch': 3.0}\n",
      "Prueba 2: lr=1e-05, batch_size=4, epochs=3, grad_steps=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rodrigo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 15:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.292800</td>\n",
       "      <td>1.284956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.280300</td>\n",
       "      <td>1.277062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.272900</td>\n",
       "      <td>1.270911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:25]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: {'eval_loss': 1.2702876329421997, 'eval_runtime': 32.0598, 'eval_samples_per_second': 1.092, 'eval_steps_per_second': 0.156, 'epoch': 3.0}\n",
      "Prueba 3: lr=1e-05, batch_size=2, epochs=3, grad_steps=2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 16:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.292800</td>\n",
       "      <td>1.283032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.276900</td>\n",
       "      <td>1.268428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.262600</td>\n",
       "      <td>1.257502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.248800</td>\n",
       "      <td>1.241922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.235400</td>\n",
       "      <td>1.227177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.222400</td>\n",
       "      <td>1.218079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.210700</td>\n",
       "      <td>1.205883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.199300</td>\n",
       "      <td>1.195691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.189400</td>\n",
       "      <td>1.184501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.180600</td>\n",
       "      <td>1.177750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.173800</td>\n",
       "      <td>1.171860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.168900</td>\n",
       "      <td>1.166217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.166200</td>\n",
       "      <td>1.166735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: {'eval_loss': 1.165602684020996, 'eval_runtime': 17.3807, 'eval_samples_per_second': 2.014, 'eval_steps_per_second': 0.288, 'epoch': 3.0}\n",
      "Prueba 4: lr=0.001, batch_size=8, epochs=7, grad_steps=4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 4:05:26, Epoch 5/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.206476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>0.015538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.001859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: {'eval_loss': 0.0016281469725072384, 'eval_runtime': 20.9302, 'eval_samples_per_second': 1.672, 'eval_steps_per_second': 0.239, 'epoch': 5.909090909090909}\n",
      "Prueba 5: lr=0.0001, batch_size=8, epochs=3, grad_steps=4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 1:39:19, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.241900</td>\n",
       "      <td>1.188464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: {'eval_loss': 1.168552279472351, 'eval_runtime': 18.5396, 'eval_samples_per_second': 1.888, 'eval_steps_per_second': 0.27, 'epoch': 2.5454545454545454}\n",
      "Prueba 6: lr=5e-05, batch_size=4, epochs=3, grad_steps=1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 19:51, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.265200</td>\n",
       "      <td>1.224209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.185400</td>\n",
       "      <td>1.136633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.089000</td>\n",
       "      <td>1.029133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.969600</td>\n",
       "      <td>0.893556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.817900</td>\n",
       "      <td>0.722118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.645400</td>\n",
       "      <td>0.552513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.486700</td>\n",
       "      <td>0.408044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.357300</td>\n",
       "      <td>0.297006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.263300</td>\n",
       "      <td>0.221951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.197400</td>\n",
       "      <td>0.168752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.153500</td>\n",
       "      <td>0.135312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.125100</td>\n",
       "      <td>0.112844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.110200</td>\n",
       "      <td>0.104081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: {'eval_loss': 0.10392394661903381, 'eval_runtime': 27.3433, 'eval_samples_per_second': 1.28, 'eval_steps_per_second': 0.183, 'epoch': 3.0}\n",
      "Prueba 7: lr=0.001, batch_size=4, epochs=3, grad_steps=2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 19:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.750100</td>\n",
       "      <td>0.203085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.095600</td>\n",
       "      <td>0.015497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.001592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.001001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: {'eval_loss': 0.000716207199729979, 'eval_runtime': 33.0473, 'eval_samples_per_second': 1.059, 'eval_steps_per_second': 0.151, 'epoch': 3.0}\n",
      "Prueba 8: lr=1e-05, batch_size=2, epochs=5, grad_steps=2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='220' max='220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [220/220 27:06, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.292400</td>\n",
       "      <td>1.284037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.276600</td>\n",
       "      <td>1.271344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.261200</td>\n",
       "      <td>1.252926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.245400</td>\n",
       "      <td>1.238630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.229400</td>\n",
       "      <td>1.222125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.213300</td>\n",
       "      <td>1.203915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.196500</td>\n",
       "      <td>1.186942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.178800</td>\n",
       "      <td>1.169181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.161200</td>\n",
       "      <td>1.152619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.143200</td>\n",
       "      <td>1.133582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.125500</td>\n",
       "      <td>1.115457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.109000</td>\n",
       "      <td>1.099819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.091400</td>\n",
       "      <td>1.082571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.075500</td>\n",
       "      <td>1.067544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.059900</td>\n",
       "      <td>1.052676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.045700</td>\n",
       "      <td>1.040355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.032700</td>\n",
       "      <td>1.027310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.022100</td>\n",
       "      <td>1.014973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.013300</td>\n",
       "      <td>1.009677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.006300</td>\n",
       "      <td>1.002498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.000900</td>\n",
       "      <td>0.999220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>0.997186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: {'eval_loss': 0.9971861839294434, 'eval_runtime': 17.6145, 'eval_samples_per_second': 1.987, 'eval_steps_per_second': 0.284, 'epoch': 5.0}\n",
      "Prueba 9: lr=1e-05, batch_size=8, epochs=5, grad_steps=1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 3:30:10, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.292700</td>\n",
       "      <td>1.285448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.276800</td>\n",
       "      <td>1.268563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.263000</td>\n",
       "      <td>1.255463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.249900</td>\n",
       "      <td>1.243590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.237600</td>\n",
       "      <td>1.232252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.226400</td>\n",
       "      <td>1.221224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.216400</td>\n",
       "      <td>1.212377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.208000</td>\n",
       "      <td>1.204660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.201400</td>\n",
       "      <td>1.198533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.196800</td>\n",
       "      <td>1.194547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.194500</td>\n",
       "      <td>1.194080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: {'eval_loss': 1.194079875946045, 'eval_runtime': 20.8887, 'eval_samples_per_second': 1.676, 'eval_steps_per_second': 0.239, 'epoch': 5.0}\n",
      "Prueba 10: lr=1e-05, batch_size=8, epochs=3, grad_steps=2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 3:36:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.293400</td>\n",
       "      <td>1.287669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.281600</td>\n",
       "      <td>1.278562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.274500</td>\n",
       "      <td>1.272990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 08:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: {'eval_loss': 1.2739086151123047, 'eval_runtime': 652.8946, 'eval_samples_per_second': 0.054, 'eval_steps_per_second': 0.008, 'epoch': 3.0}\n",
      "Prueba 11: lr=0.001, batch_size=8, epochs=3, grad_steps=2\n",
      "Prueba 12: lr=0.0001, batch_size=8, epochs=3, grad_steps=1\n",
      "Prueba 13: lr=1e-05, batch_size=8, epochs=7, grad_steps=1\n",
      "Prueba 14: lr=1e-05, batch_size=4, epochs=7, grad_steps=2\n",
      "Prueba 15: lr=0.0001, batch_size=8, epochs=7, grad_steps=4\n",
      "Prueba 16: lr=0.0005, batch_size=2, epochs=5, grad_steps=1\n",
      "Prueba 17: lr=1e-05, batch_size=2, epochs=3, grad_steps=4\n",
      "Prueba 18: lr=0.0001, batch_size=8, epochs=7, grad_steps=2\n",
      "Prueba 19: lr=0.0005, batch_size=2, epochs=7, grad_steps=4\n",
      "Prueba 20: lr=0.0001, batch_size=2, epochs=7, grad_steps=2\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import random\n",
    "from datetime import datetime\n",
    "import torch\n",
    "\n",
    "# Define los rangos de hiperpar谩metros\n",
    "learning_rates = [1e-5, 5e-5, 1e-4, 5e-4, 1e-3]\n",
    "batch_sizes = [2, 4, 8]\n",
    "num_epochs = [3, 5, 7]\n",
    "gradient_steps = [1, 2, 4]\n",
    "\n",
    "# Genera combinaciones aleatorias\n",
    "combinations = list(itertools.product(learning_rates, batch_sizes, num_epochs, gradient_steps))\n",
    "random.shuffle(combinations)\n",
    "\n",
    "# Limita el n煤mero de combinaciones a probar\n",
    "max_trials = 10\n",
    "train_results = []\n",
    "for i, (lr, bs, epochs, gs) in enumerate(combinations[:max_trials]):\n",
    "    try:\n",
    "        print(f\"Prueba {i+1}: lr={lr}, batch_size={bs}, epochs={epochs}, grad_steps={gs}\")\n",
    "        training_arguments = TrainingArguments(\n",
    "            run_name=f\"\"\"deepseek-coder-1.3b-base-{datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")}\"\"\",\n",
    "            output_dir=\"logs\",\n",
    "            num_train_epochs=epochs,\n",
    "            per_device_train_batch_size=bs,\n",
    "            gradient_accumulation_steps=gs,\n",
    "            optim=\"paged_adamw_32bit\",\n",
    "            save_steps=0,\n",
    "            logging_steps=10,\n",
    "            learning_rate=lr,\n",
    "            fp16=True,\n",
    "            bf16=False,\n",
    "            group_by_length=True,\n",
    "            logging_strategy=\"steps\",\n",
    "            evaluation_strategy='steps',\n",
    "            eval_steps=10,\n",
    "            save_strategy=\"no\",\n",
    "            gradient_checkpointing=False,\n",
    "        )\n",
    "        model = model_init()\n",
    "        trainer = Trainer(\n",
    "            model = model,\n",
    "            args=training_arguments,\n",
    "            train_dataset=train_tokenized,\n",
    "            eval_dataset=eval_tokenized,\n",
    "            data_collator=DataCollatorForSeq2Seq(\n",
    "                tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    "            )\n",
    "        )\n",
    "        trainer.train()\n",
    "        eval_results = trainer.evaluate()\n",
    "        train_results.append(eval_results)\n",
    "        print(f\"Resultados: {eval_results}\")\n",
    "        del model # eliminamos el modelo para evitar sobrecarga de memoria\n",
    "        torch.cuda.empty_cache() # limpiamos la cache para evitar sobrecarga de memoria\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # Aqu铆 puedes guardar los resultados y comparar posteriormente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. *Fine-Tuning* Final\n",
    "\n",
    "En la secci贸n anterior se prob贸 con diferentes hiperpar谩metros, observando la evoluci贸n de la *loss* de entrenamiento y validaci贸n. Aqu铆, realizaremos el **entrenamientos final** con una configuraci贸n concreta.\n",
    "\n",
    "### Fine-Tuning 1\n",
    "- `learning_rate = 0.0005`\n",
    "- `batch_size = 2`\n",
    "- `num_epochs = 3`\n",
    "- `gradient_accumulation_steps = 1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Fine-Tuning 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rodrigo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Entrenando con Fine-Tuning 1 ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rodrigo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\Rodrigo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\bitsandbytes\\autograd\\_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='2520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  80/2520 2:30:53 < 78:40:17, 0.01 it/s, Epoch 0/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.941300</td>\n",
       "      <td>0.437795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>0.064055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.028200</td>\n",
       "      <td>0.004631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.003525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.001576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.001036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.002234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deteniendo entrenamiento: eval_loss < 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/44 17:56]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deteniendo entrenamiento: eval_loss < 0.001\n",
      "Resultados Fine-Tuning 1: {'eval_loss': 0.0007878464530222118, 'eval_runtime': 1100.6203, 'eval_samples_per_second': 0.318, 'eval_steps_per_second': 0.04, 'epoch': 0.09523809523809523}\n",
      "\n",
      "Modelo Fine-Tuning 1 guardado en: models/deepseek-coder-ft1-2025-02-02-20-12-35\n",
      "Tokenizer guardado en: models/tokenizer-deepseek-coder-ft1-2025-02-02-20-12-36\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from transformers import TrainingArguments, TrainerCallback, Trainer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "# Callback para detener el entrenamiento cuando eval_loss < 0.001\n",
    "class EarlyStoppingBelowThresholdCallback(TrainerCallback):\n",
    "    def __init__(self, threshold=0.001):\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        eval_loss = kwargs[\"metrics\"].get(\"eval_loss\")\n",
    "        if eval_loss is not None and eval_loss < self.threshold:\n",
    "            print(f\"Deteniendo entrenamiento: eval_loss < {self.threshold}\")\n",
    "            control.should_training_stop = True\n",
    "\n",
    "learning_rate_1 = 0.0005\n",
    "batch_size_1 = 2\n",
    "num_epochs_1 = 3\n",
    "gradient_steps_1 = 1\n",
    "\n",
    "# Configurar argumentos de entrenamiento\n",
    "training_arguments_1 = TrainingArguments(\n",
    "    run_name=f\"deepseek-coder-1.3b-base-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\",\n",
    "    output_dir=\"logs\",\n",
    "    num_train_epochs=num_epochs_1,\n",
    "    per_device_train_batch_size=batch_size_1,\n",
    "    gradient_accumulation_steps=gradient_steps_1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=0,\n",
    "    logging_steps=10,\n",
    "    learning_rate=learning_rate_1,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    group_by_length=True,\n",
    "    logging_strategy=\"steps\",\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=10,\n",
    "    save_strategy=\"no\",\n",
    "    gradient_checkpointing=False,\n",
    ")\n",
    "\n",
    "# Inicializamos el modelo con LoRA\n",
    "model_1 = model_init()\n",
    "\n",
    "# Definimos el Trainer\n",
    "trainer_1 = Trainer(\n",
    "    model = model_1,\n",
    "    args=training_arguments_1,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=eval_tokenized,\n",
    "    data_collator=DataCollatorForSeq2Seq(\n",
    "        tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    "    ),\n",
    "    # Agregar el callback de early stopping\n",
    "    callbacks=[EarlyStoppingBelowThresholdCallback(threshold=0.001)],\n",
    ")\n",
    "\n",
    "print(\"\\n--- Entrenando con Fine-Tuning 1 ---\\n\")\n",
    "# Entrenamos\n",
    "trainer_1.train()\n",
    "\n",
    "# Evaluamos\n",
    "eval_results_1 = trainer_1.evaluate()\n",
    "print(f\"Resultados Fine-Tuning: {eval_results_1}\")\n",
    "\n",
    "# Guardamos el modelo y el tokenizer\n",
    "model_1_path = f\"models/deepseek-coder-ft-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "trainer_1.save_model(model_1_path)\n",
    "tokenizer_1_path = f\"models/tokenizer-deepseek-coder-ft-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "tokenizer.save_pretrained(tokenizer_1_path)\n",
    "\n",
    "print(f\"\\nModelo Fine-Tuning 1 guardado en: {model_1_path}\")\n",
    "print(f\"Tokenizer guardado en: {tokenizer_1_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
